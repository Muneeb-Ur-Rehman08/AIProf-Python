{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append('D:\\\\aiprof\\\\app')  # Ensure this path is correct\n",
    "sys.path.append('D:\\\\aiprof\\\\')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'app'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 11\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mlogging\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01muuid\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mapp\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvector_store\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m vector_store\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mapp\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodals\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchat\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_llm\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Conversation\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'app'"
     ]
    }
   ],
   "source": [
    "from typing import List, Dict, Optional\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from datetime import datetime\n",
    "import logging\n",
    "import uuid\n",
    "\n",
    "from app.utils.vector_store import vector_store\n",
    "from app.modals.chat import get_llm\n",
    "from models import Conversation\n",
    "from users.models import Assistant, SupabaseUser\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class ChatModule:\n",
    "    def __init__(self):\n",
    "        \"\"\"Initialize the chat module with necessary components.\"\"\"\n",
    "        self.llm = get_llm()\n",
    "        self.memory = ConversationBufferMemory(\n",
    "            memory_key=\"chat_history\",\n",
    "            return_messages=True\n",
    "        )\n",
    "        \n",
    "    def _create_prompt(self, assistant_config) -> ChatPromptTemplate:\n",
    "        \"\"\"Create a chat prompt template based on assistant configuration.\"\"\"\n",
    "        template = \"\"\"You are a teaching assistant specialized in {subject}.\n",
    "        \n",
    "        Instructions: {instructions}\n",
    "        \n",
    "        Context from knowledge base:\n",
    "        {context}\n",
    "        \n",
    "        Chat History:\n",
    "        {chat_history}\n",
    "        \n",
    "        Human Question: {question}\n",
    "        \n",
    "        Provide a clear, detailed response based on the context and your expertise. If the question cannot be fully answered using the provided context, state that clearly but provide the best possible answer from what is available.\"\"\"\n",
    "        \n",
    "        prompt = ChatPromptTemplate.from_template(template)\n",
    "        return prompt\n",
    "\n",
    "    def get_relevant_context(self, query: str, ass_id: str, k: int = 3) -> str:\n",
    "        \"\"\"Retrieve relevant context from vector store.\"\"\"\n",
    "        try:\n",
    "            results = vector_store.similarity_search(\n",
    "                query,\n",
    "                k=k,\n",
    "                filter={\"ass_id\": ass_id}\n",
    "            )\n",
    "            return \"\\n\".join([doc.page_content for doc in results])\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error retrieving context: {e}\")\n",
    "            return \"\"\n",
    "\n",
    "    def save_chat_history(self, user_id: str, ass_id: str, \n",
    "                         prompt: str, content: str, \n",
    "                         conversation_id: Optional[uuid.UUID] = None) -> None:\n",
    "        \"\"\"Save chat interaction to Django model.\"\"\"\n",
    "        try:\n",
    "            # Get the related models instances\n",
    "            user = SupabaseUser.objects.get(id=user_id)\n",
    "            assistant = Assistant.objects.get(ass_id=ass_id)\n",
    "            \n",
    "            # If no conversation_id provided, create a new one\n",
    "            if not conversation_id:\n",
    "                conversation_id = uuid.uuid4()\n",
    "            \n",
    "            # Create new conversation entry\n",
    "            Conversation.objects.create(\n",
    "                users_id=user,\n",
    "                ass_id=assistant,\n",
    "                prompt=prompt,\n",
    "                content=content,\n",
    "                conversation_id=conversation_id\n",
    "            )\n",
    "            \n",
    "            logger.info(f\"Saved chat history for conversation {conversation_id}\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error saving chat history: {e}\")\n",
    "            raise\n",
    "\n",
    "    def get_chat_history(self, ass_id: str, user_id: str, \n",
    "                        conversation_id: Optional[uuid.UUID] = None,\n",
    "                        limit: int = 10) -> List[Dict]:\n",
    "        \"\"\"Retrieve chat history from Django model.\"\"\"\n",
    "        try:\n",
    "            # Base query\n",
    "            query = Conversation.objects.filter(\n",
    "                ass_id__ass_id=ass_id,\n",
    "                users_id__id=user_id\n",
    "            )\n",
    "            \n",
    "            # Add conversation_id filter if provided\n",
    "            if conversation_id:\n",
    "                query = query.filter(conversation_id=conversation_id)\n",
    "            \n",
    "            # Get latest conversations\n",
    "            conversations = query.order_by('-created_at')[:limit]\n",
    "            \n",
    "            # Convert to list of dicts for consistency with existing code\n",
    "            return [\n",
    "                {\n",
    "                    'question': conv.prompt,\n",
    "                    'answer': conv.content,\n",
    "                    'timestamp': conv.created_at,\n",
    "                    'conversation_id': conv.conversation_id\n",
    "                }\n",
    "                for conv in conversations\n",
    "            ]\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error retrieving chat history: {e}\")\n",
    "            return []\n",
    "\n",
    "    def process_message(self, message: str, ass_id: str, \n",
    "                       user_id: str, assistant_config: dict,\n",
    "                       conversation_id: Optional[uuid.UUID] = None) -> str:\n",
    "        \"\"\"Process a chat message and generate a response.\"\"\"\n",
    "        try:\n",
    "            # Get relevant context\n",
    "            context = self.get_relevant_context(message, ass_id)\n",
    "            \n",
    "            # Create prompt\n",
    "            prompt = self._create_prompt(assistant_config)\n",
    "            \n",
    "            # Get chat history\n",
    "            chat_history = self.get_chat_history(\n",
    "                ass_id, \n",
    "                user_id, \n",
    "                conversation_id=conversation_id\n",
    "            )\n",
    "            chat_history_str = \"\\n\".join([\n",
    "                f\"Human: {chat['question']}\\nAssistant: {chat['answer']}\"\n",
    "                for chat in chat_history\n",
    "            ])\n",
    "\n",
    "            # Create chain\n",
    "            chain = (\n",
    "                {\"context\": lambda x: context,\n",
    "                 \"question\": RunnablePassthrough(),\n",
    "                 \"chat_history\": lambda x: chat_history_str,\n",
    "                 \"subject\": lambda x: assistant_config[\"subject\"],\n",
    "                 \"instructions\": lambda x: assistant_config[\"teacher_instructions\"]}\n",
    "                | prompt\n",
    "                | self.llm\n",
    "                | StrOutputParser()\n",
    "            )\n",
    "            \n",
    "            # Generate response\n",
    "            response = chain.invoke(message)\n",
    "            \n",
    "            # Save interaction\n",
    "            self.save_chat_history(\n",
    "                user_id=user_id,\n",
    "                ass_id=ass_id,\n",
    "                prompt=message,\n",
    "                content=response,\n",
    "                conversation_id=conversation_id\n",
    "            )\n",
    "            \n",
    "            return response\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error processing message: {e}\")\n",
    "            return \"I apologize, but I encountered an error processing your message. Please try again.\"\n",
    "\n",
    "    def clear_chat_history(self, ass_id: str, user_id: str, \n",
    "                          conversation_id: Optional[uuid.UUID] = None) -> bool:\n",
    "        \"\"\"Clear chat history for a specific assistant and user.\"\"\"\n",
    "        try:\n",
    "            query = Conversation.objects.filter(\n",
    "                ass_id__ass_id=ass_id,\n",
    "                users_id__id=user_id\n",
    "            )\n",
    "            \n",
    "            if conversation_id:\n",
    "                query = query.filter(conversation_id=conversation_id)\n",
    "                \n",
    "            query.delete()\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error clearing chat history: {e}\")\n",
    "            return False\n",
    "            \n",
    "    def get_conversation_list(self, user_id: str) -> List[Dict]:\n",
    "        \"\"\"Get list of unique conversations for a user.\"\"\"\n",
    "        try:\n",
    "            conversations = Conversation.objects.filter(\n",
    "                users_id__id=user_id\n",
    "            ).values(\n",
    "                'conversation_id',\n",
    "                'created_at'\n",
    "            ).distinct().order_by('-created_at')\n",
    "            \n",
    "            return [\n",
    "                {\n",
    "                    'conversation_id': str(conv['conversation_id']),\n",
    "                    'created_at': conv['created_at']\n",
    "                }\n",
    "                for conv in conversations\n",
    "            ]\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error retrieving conversation list: {e}\")\n",
    "            return []"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
